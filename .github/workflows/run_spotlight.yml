# Name your workflow
name: Run spotlight_getters and Save Data Folder

# Define when the workflow should run
on:
  # Trigger 1: On a schedule (every 3 hours)
  schedule:
    - cron: '0 */3 * * *'
  
  # Trigger 2: On pushes to the main branch
  push:
    branches: [ main ]
  
  # Trigger 3: Manually from the Actions tab
  workflow_dispatch:

# Define the jobs to run
jobs:
  run-and-archive:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Check out your repository code
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2: Set up your desired Python version
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Step 4: Run the python script
      - name: Run the python script
        working-directory: ./python
        run: python spotlight_data_fetcher.py # Assuming you are using the rewritten script name
        env:
          SPOTIFY_CLIENT_ID: ${{ secrets.SPOTIFY_CLIENT_ID }}
          SPOTIFY_CLIENT_SECRET: ${{ secrets.SPOTIFY_CLIENT_SECRET }}
          SPOTIFY_REDIRECT_URI: ${{ secrets.SPOTIFY_REDIRECT_URI }}

      # Step 5: Upload the entire 'public/data' folder as an artifact
      - name: Upload data folder
        uses: actions/upload-artifact@v4
        with:
          name: generated-data
          path: public/data/ # Correct path based on your script's output
          if-no-files-found: error # Fails the workflow if the data wasn't created